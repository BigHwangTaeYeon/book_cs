# 메모리
CPU는 메모리에 잇는 명령어를 실행한다.

### 메모리 계층
레지스터
    - 제일 빠른 메모리, 프로세서에 위치한 고속 메모리.
    - 극히 소량의 데이터나, 처리 중인 프로세서가 바로 사용할 수 있는 데이터를 담고 있는 영역
    - CPU 안에 작은 메모리, 휘발성, 가장 빠른 속도, 기억 용량이 가장 적다.
캐시
    - 레지스터 다음으로 빠른 메모리, CPU 내부에 존재. 
    - 용량은 작지만 자주 사용되는 데이터를 복사해 CPU 메모리 접근 시간을 줄요 속도를 향상.
    - CPU와 주기억장치간의 속도 차이로 인한 성능 저하를 막기 위해 사용.(병목현상을 줄임)
    - L1, L2 캐시를 지칭, 휘발성, 빠른 속도, 기억 용량이 적다. (L3 캐시도 있다.)
주기억장치
    - CPU나 메인보드와 분리되어 있는 메모리 중, 최상위 메모리.
    - HDD에서 데이터를 복사하고 임시저장하여 필요시, CPU에 빠르게 전달.
    - CPU에서 직접 접근이 가능한 메모리, 캐시보다 많이 느리지만 HDD, SSD에 비해 빠르고 보통 DRAM으로 구성
    - 대표적으로 RAM과 ROM 메모리로 존재
    - 휘발성, 속도 보통, 기억 용량이 보통
보조기억장치
    - CPU에서 직접 접근이 불가능한 메모리.
    - 디바이스 드라이버와 시스템 콜을 통해 기억장치의 특정 위치의 내용을 주기억장치로 로드하여 읽어야 접근이 가능하다.
    - SSD(Solid State Drive), HDD(Hard Disk Drive)로 구성
    - 비휘발성, 속도 낮음, 기억용량이 많다.

##### 캐시를 직접 설정
데이터를 기반으로 설정, 자주 사용하는 데이터는 지역성으로 구분한다.

- 시간 지역성(temporal locality)
    최근 사용한 데이터에 다시 접근하려는 특성
    ex) for문의 i

- 공간 지역성(spatial locality)
    최근 접근한 데이터를 이루고 있는 공간이나 가까운 공간에 접근하는 특성
    ex) for문안에 arr

##### 캐시히트와 캐시미스
캐시히트 : 원하는 데이터를 찾음
캐시미스 : 해당 데이터가 없어, 주메모리에서 찾아옴

- 캐시매핑
캐시히트가 되기 위한 매핑
CPU의 레지스터와 주메모리(RAM)간에 데이터를 주고 받을 때, 
레지스터가 캐시 계층으로써 역할을 하기 위한 매핑 처리
    직접 매핑(directed mapping) : 순서를 일치시키고 집합을 두어 처리
        처리가 빠르지만 충돌 발생이 잦음
    연관 매핑(associative mapping) : 순서 상관 없이 관련있는 메모리 매핑
        충돌이 적지만 모든 블록을 탐색하여 속도가 느림
    집합 연관 매핑(set associative mapping) : 직접 매핑과 연관 매핑을 합침
        직접 매핑처럼 순서와 블록화로 검색이 효율적(java Tree 구조)

- 웹브라우저 캐시
쿠키 : 만료기한이 있는 키 값 저장소. (보통 서버에서 만료기한을 설정)
    4KB까지 데이터 저장 가능
로컬 스토리지 : 만료기한이 없는 키 값 저장소.
    10MB까지 데이터 저장, 웹브라우저를 닫아도 유지, 도메인 단위로 저장 생성, 클라이언트에서 수정 가능
세션 스토리지 : 만료기한이 없는 키 값 저장소.
    5MB까지 데이터 저장, 탭 단위로 세션 스토리지를 생성, 탭 닫을 때 데이터 삭제, 클라이언트에서 수정 가능

** DB 시스템 구축 시, 레디스(redis) DB계층을 캐싱 계층으로 성능 향상시키기도 함 **
- 캐시히트 : 레디스에서 읽어옴
- 데이터를 레디스에 씀
- 캐시미스 : 메인 DB에서 데이터를 가져옴


### 메모리 관리

##### 가상메모리(virtual memory)
기계에 실제 이용 가능한 기억 자원을 이상적으로 추상화하여 사용자에게 큰 메모리로 보이게 만드는 것.
각 프로그램에 실제 메모리 주소가 아닌 가상의 메모리 주소를 주는 방식.
SSD나 HDD를 RAM처럼 사용하는 기술.

    - 가상주소(logical address) | 실제 메모리상에 실제 주소(physical address)
    - 가상 주소는 메모리관리장치(MMU)에 의해 실제 주소로 변환된다.
    - 가상 메모리는 가상 주소와 실제 주소가 메핑되어 있으며, 프로세스의 주소 정보가 들어있는 페이지 테이블로 관리, 이때 속도 향상을 위해 TLB 사용
        TLB : 캐시 계층으로, 메모리와 CPU 사이에 주소 변환을 위한 캐시, 페이지 테이블에 있는 리스트를 보관하여 CPU가 페이지 테이블로 가지않게한다.

- 스와핑
가상 메모리에는 존재하고 RAM에는 없는 데이터나 코드의 경우 페이지 폴트 발생
가상메모리에서 HDD로 옮겨 사용하는 것을 스와핑이라 한다.

- 페이지 폴트(page fault)
가상 메모리에는 존재하고 RAM에는 없는 데이터나 코드의 경우
    1) CPU는 RAM을 확인하고 페이지가 없으면 트랩을 발생하여 운영체제에 알림
    2) CPU는 잠시 멈춤
    3)  A. 페이지 테이블을 확인
        B. 가상 메모리에 존재여부로 확인
        C. 없으면 프로세스 중단하고 RAM에 비어있는 프레임을 찾는다.
        D. 없으면 스와핑 발동
    4) 비어있는 프레임에 페이지 로드와 페이지 테이블 최신화.
    5) CPU 다시 시작

        페이지 : 가상 메모리를 사용하는 최소 크기 단위
        프레임 : 실제 메모리를 사용하는 최소 크기 단위

##### 스레싱(thrashing)
메모리의 페이지 폴트율이 높은 것을 의미(성능 저하)
메모리에 너무 많은 프로세스가 동시에 올라가면 스와핑이 많이 일어나 발생

페이지 폴트 발생 > CPU 이용율 낮아짐 > 가용성을 높이기 위해 더 많은 프로세스를 메모리에 올림

해결방법
    1. 메모리 늘리기
    2. HDD > SSD 로 바꾸기
    3. 운영체제에서는 작업 세트와 PFF

- 작업 세트(working set)
프로세스의 과거 사용 이력인 지역성(locality)을 통해 페이지 집합을을 만들어 미리 메모리에 로드.
(탐색 비용과 스와핑을 줄일 수 있다.)

- PFF(page fault frequency)
페이지 폴트 빈도 조절 방법.
상한선과 하한선을 만드는 방법, 상한선에서는 프레임을 늘리고 하한선에서는 프레임을 줄인다.

##### 메모리 할당
시작 메모리 위치와 할당 크기 기반으로 할당을 진행.
연속 할당과 불연속 할당으로 나뉜다.

- 연속할당
메모리에 연속적으로 공간 할당

    - 고정 분할 방식(fixed partition allocation)
        메모리를 미리 나누어 관리.
        내부 단편화 발생.
    - 가변 분할 방식(variable partition allocation)
        매 시점 프로그램의 크기에 맞게 분할. 
        외부 단편화 발생
            - 최초적합 : 위 또는 아래에서 시작하여 홀을 찾으면 바로 할당
            - 최적접합 : 프로세스 크기가 가장 작은 홀부터 할당
            - 최악접합 : 프로세스 크기와 가장 많은 차이가 나는 홀에 할당
    
    - 내부 단편화(internal fragmentation) : 나눈 메모리의 크기보다 프로그램이 작아서 들어가지 못하는 현상
    - 외부 단편화(external fragmentation) : 나눈 메모리의 크기보다 프로그램이 커서 들어가지 못하는 현상
    - 홀(hole) : 비어이는 메모리 공간

- 불연속 할당
메모리를 동일한 크기의 페이지(보통 4KB)로 나누고, 프로그램마다 페이지 테이블을 두고, 메모리에 프로그램을 할당.
페이징 기법 말고도 세그멘테이션, 페이지드 세그멘테이션이 있다. 

    - 페이징
        페이지 단위로 나누어 메모리의 서로 다른 위치에 프로세스를 할당
        홀 크기의 문제는 없지만 주소 변환이 복잡한 단점

    - 세그멘테이션(segmentation)
        세그먼트로 나누는 방식 
        프로세스를 이루는 메모리는 코드영역, 데이터영역, 스택영역, 힙영역으로 이루어짐.
        코드와 데이터로 나누거나, 코드 내의 함수를 세그먼트로 나눌 수 있다.
        공유와 보안 측면에서 장점이지만 홀 크기가 균일하지 않은 단점

    - 페이지드 세그멘테이션(paged segmentation)
        세그먼트로 나누어 공유가 보안 측면에 강점을 두고
        임의의 길이가 아닌 동일한 크기의 페이지 단위로 나누는 것.

- 힙 메모리
프로그램에서 동적으로 할당된 메모리를 관리하는 데 사용되는 영역이다. 
프로그램이 실행될 때, 운영체제는 프로그램에 메모리 공간을 할당하며 공간은 스택(Stack)과 힙(Heap)으로 구성된다.

스택은 지역 변수와 함수 호출 시 생성되는 변수들을 저장하는 영역.
힙은 동적으로 할당되는 메모리를 저장하는 영역.

힙 메모리는 스택과 달리, 메모리 블록을 계속해서 할당하거나 해제할 수 있에,
메모리 누수(Memory Leak)가 발생하기 쉽다. 
메모리 누수란, 할당된 메모리를 해제하지 않은 채로 프로그램이 종료되거나,
해당 메모리를 더 이상 사용하지 않을 때 발생한다.
메모리 누수는 시스템의 성능에 영향을 미치며, 
심각한 경우 시스템 충돌을 일으킬 수 있다.
따라서, 할당된 메모리를 적절한 방법으로 해제하여 메모리 누수를 방지해야 한다.

힙 메모리는 운영체제와 프로그램 사이의 중간 영역으로써, 
프로그래머가 메모리 관리를 주도적으로 수행할 수 있는 유연성을 제공한다. 그러나 이러한 유연성은 부적절한 사용으로 인해 메모리 누수와 같은 문제를 발생시킬 수 있으므로, 프로그래머는 힙 메모리를 사용할 때 주의를 기울여야 한다.

##### 페이지 교체 알고리즘
메모리는 한정되 스와핑이 많이 일어난다.
페이지 교체 알고리즘을 기반으로 스와핑이 일어난다.

- 오프라인 알고리즘(Offline Algorithm)
사용할 페이지와 할당된 페이지를 바꾸는 알고리즘
클라이언트는 어떤 것을 사용할지 모르기에 사용할 수 없는 알고리즘.
그래서 다른 알고리즘과의 성능 비교에 대한 상한기준(upper_bound)을 제공

- FIFO(First In First Out)
가장 먼저 온 페이지를 교체 영역에 놓는 방법

- LRU(Least Recentle Used)
참조가 가장 오래된 페이지를 바꿈.
오래된 것을 파악하기 위해 페이지마다 계수기와 스택을 두어야하는 문제가 있다.

구현 시, 해시 테이블과 이중 연결 리스트 자료 구조로 구현.
해시 테이블은 이중 연결 리스트에서 빠르게 찾을 수 있고 이중 연결 리스트는 한정된 메모리를 나타낸다.

    - NUR(Not Used Recently)
        LRU에서 발전한 알고리즘, 일명 clock알고리즘이라 하며 0과 1을 가진 비트를 둔다.
        1은 최근에 참조되었고 0은 참조되지 않음을 의미한다.
        시계 방향으로 0을 찾고 0을 찾으면 프로세스를 교체하며 1로 바꾸는 알고리즘이다.

- LFU(Least Frequently Used)
    가장 참조가 적은 페이지를 교체
    즉, 많이 사용하지 않는 페이지를 교체하는 것이다.




































